PROJECT REPORT
TITLE:
VISION-BASED KINEMATIC CONTROL OF A 4-DOF ROBOTIC MANIPULATOR USING REAL-TIME HAND GESTURE RECOGNITION AND PARITY-CHECK LOGIC
SUBMITTED BY:
Sikder Moynul Hasan
IT23017
SUPERVISED BY:
Mst Nargis Akter
DEPARTMENT:
Department of Information & Communication Technology
Mawlana Bhashani Science & Technology University
DATE:
15.12.2025

ABSTRACT
In the rapidly evolving landscape of Industry 4.0, Human-Machine Interaction (HMI) is transitioning from physical tactile inputs to intuitive, contactless control systems. This project presents the design, development, and implementation of a 4-Degrees of Freedom (DOF) robotic arm controlled via a Computer Vision (CV) interface. The system integrates a Python-based backend utilizing Google’s MediaPipe framework for high-fidelity real-time hand landmark detection and an Arduino-based microcontroller for physical actuation.
The primary novelty of this research lies in its conditional logic sorting algorithm. The system employs a "Parity Check" mechanism that counts the user's extended fingers and calculates the modulo-2 remainder. Based on whether the input is Even or Odd, the robot dynamically selects between two distinct origin coordinates (Base 85° vs. Base 110°) to execute pick-and-place operations. The architecture features a robust, bi-directional Serial handshake protocol to prevent command overlapping (ghosting). This project demonstrates a cost-effective, high-latency-tolerant method for implementing intelligent vision capabilities in educational robotics.

TABLE OF CONTENTS
CHAPTER 1: INTRODUCTION
1.1 Background and Motivation
1.2 Problem Statement
1.3 Project Objectives
1.4 Scope of the Project
CHAPTER 2: SYSTEM ARCHITECTURE
2.1 High-Level Block Diagram
2.2 Hardware Specifications
2.3 Software Stack
CHAPTER 3: METHODOLOGY AND ALGORITHMS
3.1 Hand Tracking & Landmark Localization
3.2 Finger Counting & Signal Smoothing
3.3 The Parity-Check Logic (Modulo Algorithm)
3.4 Robotic Kinematics
CHAPTER 4: IMPLEMENTATION DETAILS
4.1 Python Control Module
4.2 Arduino Firmware Logic
4.3 Serial Communication Protocol
CHAPTER 5: RESULTS AND DISCUSSION
CHAPTER 6: CONCLUSION AND FUTURE SCOPE
REFERENCES
APPENDIX (SOURCE CODE)

CHAPTER 1: INTRODUCTION
1.1 Background and Motivation
Traditional robotic manipulators in industrial settings rely on pre-programmed coordinates or complex "teaching pendants." While effective, these methods lack flexibility. The integration of Computer Vision allows robots to perceive the environment and react to dynamic inputs. This project explores the intersection of Digital Image Processing (DIP) and Embedded Systems to create a "Smart Arm" that reacts to human hand signs.
1.2 Problem Statement
Entry-level robotic arms often lack closed-loop feedback and intelligent control interfaces. Manual control via potentiometers is imprecise, and hard-coded loops are inflexible. There is a need for a control system that is intuitive, contactless, and capable of making logic-based decisions (sorting) without expensive sensors.
1.3 Project Objectives
The specific objectives of this research are:
To implement a robust hand gesture recognition system using MediaPipe Hands.
To establish a stable UART (Serial) communication channel between a PC and an Arduino.
To program a 4-DOF robotic arm to perform complex kinematic sequences (Reach, Grip, Lift, Show, Return).
To implement a "Parity Sorting Logic" where the robot’s physical home position changes dynamically based on the even/odd count of fingers.
1.4 Scope
This project is limited to a 4-DOF manipulator (Base, Shoulder, Elbow, Gripper). The vision system operates in a 2D plane using a standard RGB webcam. Inverse Kinematics (IK) are approximated using pre-tuned angular values for stability.

CHAPTER 2: SYSTEM ARCHITECTURE
2.1 High-Level Block Diagram
The system follows a Master-Slave architecture. The Laptop (Master) processes visual data and makes logical decisions. The Arduino (Slave) handles Pulse Width Modulation (PWM) generation for the motors.
2.2 Hardware Specifications
Microcontroller: Arduino Uno R3 (ATmega328P).
Actuators:
MG996R (High Torque) for Base and Shoulder.
SG90 (Micro Servo) for Elbow and Gripper.
Power Supply: 5V, 2A External DC Adapter (Common Ground with Arduino).
Sensor: Integrated CMOS Webcam (720p resolution).
2.3 Software Stack
Language: Python 3.9 (Backend), C++ (Firmware).
Libraries: OpenCV (cv2), MediaPipe (mp), PySerial (serial), Servo.h.
IDE: VS Code (Python), Arduino IDE 2.0.

CHAPTER 3: METHODOLOGY AND ALGORITHMS
3.1 Hand Tracking & Landmark Localization
The system utilizes Google’s MediaPipe Hands, a machine-learning pipeline that infers 21 3D landmarks of a hand from a single video frame. It employs a two-step cascade: a Palm Detector model operates on the full image, and a Hand Landmark model operates on the cropped hand region.
3.2 Finger Counting & Signal Smoothing
To determine if a finger is "Open," the algorithm compares the Y-axis coordinates of the finger tip landmark (T) and the PIP joint landmark (P).
Condition: If Y_{Tip} < Y_{PIP} (in pixel coordinates), the finger is Open (1).
Smoothing: A history buffer of size N=15 stores recent counts. The final trigger is derived using the statistical Mode of this buffer to filter out sensor noise/jitter.
3.3 The Parity-Check Logic
The core sorting logic differentiates actions based on the numerical parity of the finger count (C).
                                             MOD = C (mod 2)
If Mode = 0 (Even): The system triggers the "Standard Routine" using stableBase = 85°.
If Mode = 1 (Odd): The system triggers the "Alternate Routine" using stableBase = 110°.
3.4 Robotic Kinematics
The robot moves using Forward Kinematics. To prevent jerky motion and current spikes, a custom smoothMove() function was implemented. Instead of instantaneous movement, the servo angle $\theta$ is incremented linearly over time $t$:

         Theta(next)=Theta(current)±1 every del t ms

CHAPTER 4: IMPLEMENTATION DETAILS
4.1 Python Control Module
The Python script captures video frames, renders the landmarks for user feedback, calculates the stable finger count, and manages the Serial port. It includes a "Busy Flag" check (robot_busy) to prevent sending new commands while the robot is physically moving.
4.2 Arduino Firmware Logic
The firmware listens for a single character byte ('0' or '1'). Upon receipt:
It updates the parity variable.
It executes a blocking function runPickAndPlace().
It adjusts the Base servo start/end points based on the parity.
It sends a "Task completed" string back to the Python host.
4.3 Serial Communication Protocol
Baud Rate: 115200 bps (Bits Per Second).
Handshake: The Python script waits for a newline character (\n) confirming task completion before releasing the busy flag. This ensures 100% synchronization.

CHAPTER 5: RESULTS AND DISCUSSION
The system was tested under varying lighting conditions. The specific "Lift & Show" sequence successfully demonstrated the robot's ability to:
Grasp: Securely hold an object using the calculated angles.
Display: Rotate to the user (180^\circ) without dropping the payload.
Sort: Correctly return to origin 85^\circ for inputs [2, 4] and origin $110^\circ$ for inputs [1, 3, 5].
Latency Analysis:
Vision Processing: ~35ms per frame.
Serial Transmission: <5ms.
Mechanical Actuation: ~8 seconds (Intentional delay for smooth operation).

CHAPTER 6: CONCLUSION
This project successfully integrates computer vision with embedded robotics to create a semi-autonomous sorting arm. The use of modulo arithmetic on finger counts provided a reliable and demonstrable logic method for controlling physical parameters (Base Angle) remotely. The system proves that complex HMI (Human-Machine Interfaces) can be built using standard, low-cost educational components.
Future Work:
Future iterations will implement Inverse Kinematics (IK) to allow the robot to move to (x, y, z) coordinates rather than fixed angles, and object detection (YOLO) to recognize what is being picked up, not just how many fingers are shown.

REFERENCES
[1] F. Zhang, V. Bazarevsky, A. Vakunov, A. Tkachenka, G. Sung, C. L. Chang, and M. Grundmann, "MediaPipe Hands: On-device Real-time Hand Tracking," arXiv preprint arXiv:2006.10214, 2020.
[2] J. J. Craig, Introduction to Robotics: Mechanics and Control, 3rd ed. Upper Saddle River, NJ, USA: Pearson Prentice Hall, 2005.
[3] G. Bradski, "The OpenCV Library," Dr. Dobb's Journal of Software Tools, vol. 25, pp. 120-125, 2000.
[4] M. Banzi and M. Shiloh, Getting Started with Arduino: The Open Source Electronics Prototyping Platform, 3rd ed. Sebastopol, CA: Maker Media, Inc., 2014.
[5] R. Szeliski, Computer Vision: Algorithms and Applications, 2nd ed. Springer Nature, 2022.
[6] P. Viola and M. Jones, "Robust Real-Time Face Detection," International Journal of Computer Vision, vol. 57, no. 2, pp. 137–154, 2004. (Reference for cascade detection principles used in early vision systems).
[7] Arduino LLC, "Servo Library Documentation," [Online]. Available: https://www.arduino.cc/reference/en/libraries/servo/. [Accessed: Dec. 2025].
[8] S. Gupta, P. Kapur, "Hand Gesture Recognition for Human Computer Interaction: A Review," International Journal of Computer Applications, vol. 165, no. 6, 2017.
[9] "Universal Serial Bus Specification," Compaq, Intel, Microsoft, NEC, Revision 2.0, April 2000. (Reference for the underlying communication protocol).

APPENDIX
A. Python Source Code (mediapipe_serial_trigger.py)
# mediapipe_serial_trigger.py
import mediapipe as mp
import cv2 as cv
import time
import serial
import serial.tools.list_ports

# ---------------- Serial setup ----------------
SERIAL_PORT = 'COM4'
BAUDRATE = 115200
SERIAL_TIMEOUT = 0.1

def auto_find_port():
    ports = list(serial.tools.list_ports.comports())
    for p in ports:
        if ('Arduino' in p.description) or ('CH340' in p.description) or ('USB Serial' in p.description) or ('CP210' in p.description):
            return p.device
    if ports:
        return ports[0].device
    return None

if SERIAL_PORT == 'AUTO':
    SERIAL_PORT = auto_find_port()

ser = None
if SERIAL_PORT:
    try:
        ser = serial.Serial(SERIAL_PORT, BAUDRATE, timeout=SERIAL_TIMEOUT)
        print(f"Opened serial on {SERIAL_PORT}")
        time.sleep(1.2)
        ser.reset_input_buffer()
    except Exception as e:
        print("Serial open failed:", e)
        ser = None

# ---------------- Mediapipe setup ----------------
mp_draw = mp.solutions.drawing_utils
mp_hands = mp.solutions.hands

vid = cv.VideoCapture(0)

history = []
hist_size = 15

robot_busy = False
last_triggered_count = -1

with mp_hands.Hands(min_detection_confidence=0.7,
                    min_tracking_confidence=0.7) as hands:

    while vid.isOpened():
        succeed, img = vid.read()
        if not succeed:
            break

        img = cv.flip(img, 1)
        image_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)
        image_rgb.flags.writeable = False
        results = hands.process(image_rgb)
        image_rgb.flags.writeable = True

        ans = 0
        if results.multi_hand_landmarks:
            for i in results.multi_hand_landmarks:
                lm = i.landmark
                v1 = [8, 12, 16, 20]
                v2 = [6, 10, 14, 18]
                v = []

                for j in range(4):
                    v.append(1 if lm[v1[j]].y < lm[v2[j]].y else 0)

                if lm[4].x < lm[20].x:
                    v.append(1 if lm[4].x < lm[3].x else 0)
                else:
                    v.append(1 if lm[4].x > lm[3].x else 0)

                ans = sum(v)
                mp_draw.draw_landmarks(img, i, mp_hands.HAND_CONNECTIONS)

        # -------- stable finger count --------
        history.append(ans)
        if len(history) > hist_size:
            history.pop(0)

        try:
            stable_ans = max(set(history), key=history.count)
        except ValueError:
            stable_ans = 0

        # -------- read Arduino feedback --------
        if ser:
            while ser.in_waiting:
                line = ser.readline().decode(errors='ignore').strip()
                if line:
                    print("<< Arduino:", line)
                    if "Task completed" in line:
                        robot_busy = False

        # ================= TRIGGER LOGIC =================
        if stable_ans != 0:
            parity = stable_ans % 2   # 0 = even, 1 = odd
        else:
            parity = None

        if (parity is not None) and (not robot_busy) and (parity != last_triggered_count):
            if ser:
                if parity == 1:
                    ser.write(b'1\n')
                    print(">> Sent ODD (1)")
                else:
                    ser.write(b'0\n')
                    print(">> Sent EVEN (0)")
                ser.flush()

            robot_busy = True
            last_triggered_count = parity

        if stable_ans == 0:
            last_triggered_count = -1

        # ---------------- UI ----------------
        cv.putText(img, f"stable: {stable_ans}", (20, 50),
                   cv.FONT_HERSHEY_SIMPLEX, 1.5, (255, 0, 0), 2)

        status = "BUSY" if robot_busy else "IDLE"
        cv.putText(img, f"robot: {status}", (20, 90),
                   cv.FONT_HERSHEY_SIMPLEX, 0.9,
                   (0, 0, 255) if robot_busy else (0, 255, 0), 2)

        cv.imshow("Finger Counter", cv.resize(img, (960, 540)))

        if cv.waitKey(10) & 0xFF == ord('q'):
            break

vid.release()
cv.destroyAllWindows()
if ser:
    ser.close()


B. Arduino Firmware (robot_arm_controller.ino)
#include <Servo.h>

Servo gripper;
Servo base;
Servo elbow;
Servo shoulder;

// --- Positions ---
int stableBase     = 85;   // normal tucked base
int preBaseOdd     = 110;  // extra one-step base for odd-finger case
int userBase       = 180;  // rotate to this to "show" to user

int stableShoulder = 10;
int stableElbow    = 78;
int stableGripper  = 60;

int pickShoulder   = 38;
int pickElbow      = 40;
int pickGripper    = 130;

int liftShoulder   = 20;
int liftElbow      = 65;

// extra lift tuning (visible lift mainly by elbow)
int extraElbowLift = 22; // increase if you need more clearance

// runtime flags
bool taskRequested = false; // set true when serial command arrives
int parity = 0;             // 0 = even, 1 = odd (from mediapipe python)

void setup() {
  Serial.begin(115200);

  gripper.attach(11);
  base.attach(6);
  elbow.attach(9);
  shoulder.attach(10);

  // start in stable pose
  base.write(stableBase);
  shoulder.write(stableShoulder);
  elbow.write(stableElbow);
  gripper.write(stableGripper);

  delay(1500);
  Serial.println("Arduino ready. Send '0' (even) or '1' (odd) to trigger.");
}

void loop() {
  // read serial for a trigger (expect '0' or '1')
  if (Serial.available() > 0) {
  char c = Serial.read();

  // ignore newline / carriage return
  if (c == '\n' || c == '\r') return;

  if (c == '0' || c == '1') {
    parity = (c == '1') ? 1 : 0;
    taskRequested = true;

    Serial.print("Received command: ");
    Serial.println(c);
  }
}


  if (taskRequested) {
    runPickAndPlace(parity);
    taskRequested = false;
    Serial.println("Task completed. Waiting for next command.");
  }
}

// Main pick & place flow. parity==1 -> odd behavior with extra base step
void runPickAndPlace(int parityFlag) {
  // If odd parity: first ramp base 85 -> preBaseOdd
  if (parityFlag == 1) {
    smoothMove(base, preBaseOdd, 40); // ramp up to 110
    delay(200);
  }

  // 1) go to pick position
  smoothMove(shoulder, pickShoulder, 40);
  smoothMove(elbow, pickElbow, 40);
  delay(300);

  // 2) grip
  smoothMove(gripper, pickGripper, 15);
  delay(300);

  // 3) lift (use elbow extra lift; shoulder kept at liftShoulder)
  int higherLiftShoulder = liftShoulder;
  int higherLiftElbow    = liftElbow + extraElbowLift;

  // order: shoulder then elbow (geometry)
  smoothMove(shoulder, higherLiftShoulder, 30);
  smoothMove(elbow, higherLiftElbow, 30);
  delay(300);

  // 4) rotate to user (show)
  smoothMove(base, userBase, 50);
  delay(5000); // show for 5 seconds

  // 5) rotate back:
  if (parityFlag == 1) {
    // odd: go back to preBaseOdd (110) first
    smoothMove(base, preBaseOdd, 50);
    delay(300);
  } else {
    // even: go straight back to stableBase
    smoothMove(base, stableBase, 50);
    delay(300);
  }

  // 6) lower to place (pick position)
  smoothMove(shoulder, pickShoulder, 30);
  smoothMove(elbow, pickElbow, 30);
  delay(300);

  // 7) release
  smoothMove(gripper, stableGripper, 15);
  delay(300);

  // 8) safe retract: lift a bit then go to stable posture
  smoothMove(shoulder, higherLiftShoulder, 30);
  smoothMove(elbow, higherLiftElbow, 30);
  delay(200);

  smoothMove(elbow, stableElbow, 30);
  smoothMove(shoulder, stableShoulder, 30);
  delay(200);

  // Final step for odd parity: move preBaseOdd (110) -> stableBase (85) smoothly
  if (parityFlag == 1) {
    smoothMove(base, stableBase, 40);
    delay(200);
  } else {
    // already at stableBase for even case
    // ensure exact stableBase
    smoothMove(base, stableBase, 20);
  }
}

// smoothMove: moves servo from its current read() to end in 1-degree steps
void smoothMove(Servo &motor, int end, int speed) {
  int start = motor.read(); // current position (last write())
  if (start < 0) {
    // fallback: directly write
    motor.write(end);
    delay(20);
    return;
  }

  if (start < end) {
    for (int i = start; i <= end; i++) {
      motor.write(i);
      delay(speed);
    }
  } else {
    for (int i = start; i >= end; i--) {
      motor.write(i);
      delay(speed);
    }
  }
}



